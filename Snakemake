# load required library
import pandas as pd

# Function to load sample information and return paired reads
def load_sample_pairs():
    file_path = "C:/Users/Parth Doshi/Desktop/ATAC-seq/ATAC-seq-peak-calling/Sample_Paired_end_Info.csv"
    paired_end_info = pd.read_csv(file_path)
    return list(zip(paired_end_info['File accession'], paired_end_info['Paired with']))

# Rule to download data files based on URLs listed in files.txt
rule download_raw_files:
    input:
        "files.txt"
    output:
        expand("DATA/{filename}", filename=[line.split('/')[-1] for line in open("files.txt").read().splitlines()])
    shell:
        """
        xargs -L 1 curl -O -J -L < {input}
        """

# Rule to perform quality control using FastQC
rule fastqc:
    input:
        expand("DATA/{{sample}}")
    output:
        html="fastqc_reports/{sample}_fastqc.html"
    params:
        outdir="fastqc_reports"
    container:
             "doshiparth2219822/bioinformatics-tool:latest"
    shell:
        """
        fastqc {input} --outdir {params.outdir}
        """

# Rule to orchestrate quality control for each paired read
rule qc_each_pair:
    input:
        load_sample_pairs
    output:
        expand("fastqc_reports/{sample}_fastqc.html", sample=lambda wc: [read for pair in load_sample_pairs() for read in pair])
    shell:
        """
        for read in {input}:
            snakemake fastqc sample={read}
        """

# Rule to aggregate all final targets
rule all:
    input:
        expand("fastqc_reports/{sample}_fastqc.html", sample=lambda wc: [read for pair in load_sample_pairs() for read in pair])




































































